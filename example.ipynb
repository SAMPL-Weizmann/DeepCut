{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import segment\n",
    "import torch\n",
    "import util\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#Parameters initialization and model download\n",
    "## If you're running on cpu please consider to change stride value to 4, this will invoke lower resolution but faster running time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# Mode\n",
    "################################################################################\n",
    "# mode == 0 Single stage segmentation\n",
    "# mode == 1 Two stage segmentation for foreground\n",
    "# mode == 2 Two stage segmentation on background and foreground\n",
    "mode = 0\n",
    "################################################################################\n",
    "# Clustering function\n",
    "################################################################################\n",
    "# NCut == 0\n",
    "# CC == 1\n",
    "# alpha = k-sensetivity parameter\n",
    "cut = 0\n",
    "alpha = 3\n",
    "################################################################################\n",
    "# GNN parameters\n",
    "################################################################################\n",
    "# Numbers of epochs per stage [mode0,mode1,mode2]\n",
    "epochs = [10, 100, 15]\n",
    "# Number of steps per image\n",
    "step = 1\n",
    "# Number of clusters\n",
    "K = 2\n",
    "################################################################################\n",
    "# Processing parameters\n",
    "################################################################################\n",
    "# Show only largest component in segmentation map (for k == 2)\n",
    "cc = False\n",
    "# apply bilateral solver\n",
    "bs = False\n",
    "# Apply log binning to extracted descriptors (correspond to smoother segmentation maps)\n",
    "log_bin = False\n",
    "################################################################################\n",
    "# Descriptors extraction parameters\n",
    "################################################################################\n",
    "# Directory to pretrained Dino\n",
    "pretrained_weights = './dino_deitsmall8_pretrain_full_checkpoint.pth'\n",
    "# Resolution for dino input, higher res != better performance as Dino was trained on (224,224) size images\n",
    "res = (224, 224)\n",
    "# stride for descriptor extraction\n",
    "stride = 8\n",
    "# facet fo descriptor extraction (key/query/value)\n",
    "facet = 'key'\n",
    "# layer to extract descriptors from\n",
    "layer = 11\n",
    "################################################################################\n",
    "# Data parameters\n",
    "################################################################################\n",
    "# Directory of image to segment\n",
    "in_dir = './images/single/'\n",
    "out_dir = './results'\n",
    "save = False\n",
    "################################################################################\n",
    "# Check for mistakes in given arguments\n",
    "if K != 2 and cc:\n",
    "    print('largest connected component only available for k == 2')\n",
    "    exit()\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# If directory doesn't exist; trigger download\n",
    "if not os.path.exists(pretrained_weights):\n",
    "    url = 'https://dl.fbaipublicfiles.com/dino/dino_deitsmall8_pretrain/dino_deitsmall8_pretrain_full_checkpoint.pth'\n",
    "    util.download_url(url, pretrained_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Single Object Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "segment.GNN_seg(mode, cut, alpha, epochs, K, pretrained_weights, in_dir, out_dir, save, cc, bs, log_bin, res, facet, layer, stride,\n",
    "            device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Let's apply bilateral solver to get more accurate segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "bs = True\n",
    "segment.GNN_seg(mode, cut, alpha, epochs, K, pretrained_weights, in_dir, out_dir, save, cc, bs, log_bin, res, facet, layer, stride,\n",
    "            device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Let's apply semantic segmentation to the foreground object using the 2-step process.\n",
    "First find the foreground object and then apply the segmentation algorithm recursively\n",
    "on the foreground object. This allows for more detailed segmentations (details in the paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "bs = False\n",
    "mode = 1\n",
    "K = 4\n",
    "segment.GNN_seg(mode, cut, alpha, epochs, K, pretrained_weights, in_dir, out_dir, save, cc, bs, log_bin, res, facet, layer, stride,\n",
    "            device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Let's apply semantic segmentation to the background and foreground objects with the 2-step method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "mode = 2\n",
    "K = 4\n",
    "segment.GNN_seg(mode, cut, alpha, epochs, K, pretrained_weights, in_dir, out_dir, save, cc, bs, log_bin, res, facet, layer, stride,\n",
    "            device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "#Let's look on more birds: ðŸ‘Š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "in_dir = './images/birds'\n",
    "segment.GNN_seg(mode, cut, alpha, epochs, K, pretrained_weights, in_dir, out_dir, save, cc, bs, log_bin, res, facet, layer, stride,\n",
    "            device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
